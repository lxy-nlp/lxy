{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zeros() received an invalid combination of arguments - got (Tensor, dtype=torch.dtype), but expected one of:\n * (tuple of ints size, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3b0c63faf5a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# 5*3 matrix 未初始化\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: zeros() received an invalid combination of arguments - got (Tensor, dtype=torch.dtype), but expected one of:\n * (tuple of ints size, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "x=torch.empty(5,3)# 5*3 matrix 未初始化\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#创建张量\n",
    "torch.zeros(5,3,dtype=torch.long)#矩阵中的元素全部是0\n",
    "torch.ones(5,3,dtype=torch.long)#矩阵中的元素全部是1\n",
    "torch.rand(5,3)# 生成【0,1】之间的随机数\n",
    "torch.randn(5,3)# 生成均值为0，方差为1的随机数，服从标准正态分布\n",
    "torch.randint(-100,100,(400,))# low high size size是一个元祖\n",
    "a=torch.tensor([5.5,3])#直接从已有的值生成张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#根据已有的形状创建张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.new_ones(6,3,dtype=torch.double) # 可以将原始矩阵的形状和值都改变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9451,  1.0759,  1.3454],\n",
       "        [ 0.4922, -0.5754,  0.2980],\n",
       "        [-0.6768,  1.1228,  1.8498],\n",
       "        [-0.7612,  0.2857, -1.2376],\n",
       "        [-1.1954, -1.5116, -0.6906]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn_like(x,dtype=torch.float)# 随机生成与x形状相同的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3628, 0.0617, 0.2691],\n",
       "        [0.6244, 0.1997, 0.4567],\n",
       "        [0.8555, 0.8259, 0.9036],\n",
       "        [0.0907, 0.3769, 0.9663],\n",
       "        [0.5217, 0.8513, 0.7195],\n",
       "        [0.2099, 0.5936, 0.3005]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.rand_like(x,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 7, 0, 1, 8, 2, 9, 5, 3, 6])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(10) # 生成一个0～n-1的随机序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5498, -1.5229, -0.3287,  0.0794],\n",
      "        [-0.2015,  0.7999, -1.1332,  0.0629],\n",
      "        [-2.0174,  0.1151,  1.8148, -1.1954],\n",
      "        [ 0.5203,  0.8745, -0.4676,  1.0320]])\n",
      "tensor([[ 1.5498, -1.5229, -0.3287,  0.0794, -0.2015,  0.7999, -1.1332,  0.0629],\n",
      "        [-2.0174,  0.1151,  1.8148, -1.1954,  0.5203,  0.8745, -0.4676,  1.0320]])\n"
     ]
    }
   ],
   "source": [
    "#改变形状 相当于numpy中的reshape\n",
    "x=torch.randn(4,4)\n",
    "print(x)\n",
    "# y=x.view(2,8)\n",
    "y=x.view(-1,8)# -1代表的是不确定的数\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.5229,  0.7999])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 访问元素\n",
    "x[:2]#取得前两行\n",
    "x[:2,1]#取得前两行的第二列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 2. 2.]\n",
      " [2. 2. 2.]\n",
      " [2. 2. 2.]\n",
      " [2. 2. 2.]\n",
      " [2. 2. 2.]]\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# tensor转换为numpy数组\n",
    "import numpy as np \n",
    "b=torch.ones(5,3)\n",
    "a = b.numpy()\n",
    "a\n",
    "#numpy数组转换为tensor\n",
    "p=np.ones(5)\n",
    "q=torch.from_numpy(a)\n",
    "#numpy中的广播机制\n",
    "np.add(a,1,out=a)\n",
    "print(a)\n",
    "print(p)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.0995, -3.0458, -0.6574,  0.1588, -0.4030,  1.5998, -2.2663,  0.1259],\n",
       "        [-4.0349,  0.2301,  3.6296, -2.3907,  1.0407,  1.7489, -0.9352,  2.0640]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=b=y\n",
    "#torch中的广播机制\n",
    "result=torch.add(a,b)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用cuda\n",
    "if torch.cuda.is_available():\n",
    "    device=torch.device(\"cuda\")\n",
    "    y=torch.ones_like(x,device=device)\n",
    "    x = x.to(\"cuda\")\n",
    "    z=x+y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\",torch.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x7f29e231a6d8>\n",
      "tensor(27., grad_fn=<MeanBackward0>)\n",
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>)\n",
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.ones(2,2,requires_grad=True)# requires_grad=True 目的是\n",
    "x\n",
    "y=x+2\n",
    "y\n",
    "print(y.grad_fn)\n",
    "z=y*y*3\n",
    "out = z.mean()\n",
    "print(out)\n",
    "print(z)\n",
    "out.backward()# 反向传播应用在标量上\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tor",
   "language": "python",
   "name": "tor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}