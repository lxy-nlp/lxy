{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "'''\n",
    "    pytorch\n",
    "    1. 张量的概念 含义 创建 更改\n",
    "    2. 求导 神经网络参数调整的过程 权重表示调整速度的快慢\n",
    "    3. 损失函数\n",
    "     \n",
    "    \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    张量操作\n",
    "'''\n",
    "x=torch.empty(5,3)# 5*3 matrix 未初始化\n",
    "torch.zeros(5,3,dtype=torch.long)#矩阵中的元素全部是0\n",
    "torch.ones(5,3,dtype=torch.long)#矩阵中的元素全部是1\n",
    "torch.rand(5,3)# 生成【0,1】之间的随机数\n",
    "torch.randn(5,3)# 生成均值为0，方差为1的随机数，服从标准正态分布\n",
    "torch.randint(-100,100,(400,))# low high size size是一个元祖\n",
    "a=torch.tensor([5.5,3])#直接从已有的值生成张量\n",
    "\n",
    "#根据已有的形状创建张量\n",
    "x = x.new_ones(6,3,dtype=torch.double) # 可以将原始矩阵的形状和值都改变\n",
    "\n",
    "x = torch.randn_like(x,dtype=torch.float)# 随机生成与x形状相同的\n",
    "\n",
    "x=torch.rand_like(x,dtype=torch.float)\n",
    "\n",
    "torch.randperm(10) # 生成一个0～n-1的随机序列\n",
    "#改变形状 相当于numpy中的reshape\n",
    "x=torch.randn(4,4)\n",
    "# y=x.view(2,8)\n",
    "y=x.view(-1,8)# -1代表的是不确定的数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.5229,  0.7999])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 访问元素\n",
    "x[:2]#取得前两行\n",
    "x[:2,1]#取得前两行的第二列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 2. 2.]\n",
      " [2. 2. 2.]\n",
      " [2. 2. 2.]\n",
      " [2. 2. 2.]\n",
      " [2. 2. 2.]]\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# tensor转换为numpy数组\n",
    "import numpy as np \n",
    "b=torch.ones(5,3)\n",
    "a = b.numpy()\n",
    "a\n",
    "#numpy数组转换为tensor\n",
    "p=np.ones(5)\n",
    "q=torch.from_numpy(a)\n",
    "#numpy中的广播机制\n",
    "np.add(a,1,out=a)\n",
    "print(a)\n",
    "print(p)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.0995, -3.0458, -0.6574,  0.1588, -0.4030,  1.5998, -2.2663,  0.1259],\n",
       "        [-4.0349,  0.2301,  3.6296, -2.3907,  1.0407,  1.7489, -0.9352,  2.0640]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=b=y\n",
    "#torch中的广播机制\n",
    "result=torch.add(a,b)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用cuda\n",
    "if torch.cuda.is_available():\n",
    "    device=torch.device(\"cuda\")\n",
    "    y=torch.ones_like(x,device=device)\n",
    "    x = x.to(\"cuda\")\n",
    "    z=x+y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\",torch.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x7f29e231a6d8>\n",
      "tensor(27., grad_fn=<MeanBackward0>)\n",
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>)\n",
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.ones(2,2,requires_grad=True)# requires_grad=True 目的是\n",
    "x\n",
    "y=x+2\n",
    "y\n",
    "print(y.grad_fn)\n",
    "z=y*y*3\n",
    "out = z.mean()\n",
    "print(out)\n",
    "print(z)\n",
    "out.backward()# 反向传播应用在标量上\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tor",
   "language": "python",
   "name": "tor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}